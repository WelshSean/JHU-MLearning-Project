---
title: "Quantified Self Movement - Quality of Exercise"
author: "Sean Clarke"
date: "14 September 2015"
output: html_document
---
```{r}
library(caret)
library(randomForest)
set.seed(1974)
```
# Data preparation

```{r}
# Download the data if we dont have it, then load te training data
DataDir <- "Data"
FilePathTrain <- paste(DataDir, "pml-training.csv", sep="/")
FilePathTest <- paste(DataDir, "pml-testing.csv", sep="/")
dir.create(DataDir, showWarnings=FALSE) 

## Only download if the file doesnt exist
if (! file.exists(FilePathTrain)){
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",FilePathTrain , method="curl")
}
if (! file.exists(FilePathTest)){
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",FilePathTest , method="curl")
}
pmltraining <- read.csv(FilePathTrain, stringsAsFactors = FALSE, na.strings = c("", "NA", "#DIV/0!"))
```

When we read in the data, we tidy up some of the mess including NA as a string, "DIV/0!" and null cells by using the na.strings argument to read.csv. After doing this, we remove the first 7 columns as they contain extraneous tracking information and we also remove the  columns that contain nothing but NAs so we remove those and we convert classes to factors

```{r}
pmltraining <- pmltraining[-(1:7)]
pmltraining <- pmltraining[, colSums(is.na(pmltraining)) != nrow(pmltraining)]
pmltraining$classe <- factor(pmltraining$classe)
```

If we look at the variables in the dataset, we see that some summarised data is included (maximum/minimum/mean.standard deviation/variance) - we proceed to remove these variables from the dataset.

```{r}
columnsToRemove <- grep("^var.*|^stddev.*|^max.*|^min.*|^avg.*|^total.*|.*timestamp.*|user_name",names(pmltraining))
pmltraining <- pmltraining[-columnsToRemove]
```

Next we remove any predictors with near-zero variance.

```{r}
last <- ncol(pmltraining)
nzv <- nearZeroVar(pmltraining[,-last], saveMetrics=FALSE)
pmltraining <- pmltraining[-nzv]
```

# Data snipped from Web Page

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. Participants were supervised by an experienced weight lifter to make sure the execution complied to the manner they were supposed to simulate. The exercises were performed by six male participants aged between 20-28 years, with little weight lifting experience. We made sure that all participants could easily simulate the mistakes in a safe and controlled manner by using a relatively light dumbbell (1.25kg).

Read more: http://groupware.les.inf.puc-rio.br/har#dataset#ixzz3ljr8Yz7M

# Model Building

Fit Initial Model in order to identify the importance of the predictors. We will use k-fold validation in order to allow us to cross-validate the model to improve the accuracy.

We notice that we have a considerable number of missing values still.
```{r}
nrow(pmltraining)
sum(complete.cases(pmltraining))
```

As a result of this we pick the Recursive Partitioning and Regression Trees (rpart) algorithm as it copes well with missing values unlike some other algorithms such as Random Forest.

```{r}
observed <- c()
predicted <- c()
folds <- createFolds(y=pmltraining$classe, k=10, list = TRUE, returnTrain = TRUE)
for (i in 1:10){
  foldtrain <- pmltraining[folds[[i]],]
  foldtest <- pmltraining[-folds[[i]],]
  foldfit <- train(classe ~ ., data = pmltraining, method="rpart")
  observed <- c(observed, foldtest$classe)
  predicted <- c(predicted, predict(foldfit, foldtest))
  print(i)
} 
```

#```{r}
#testfit <- train(classe ~ ., data = pmltraining, method="rf",importance=TRUE)
##varImp(testfit)[[1]][1:20,]
#vi <- varImp(testfit, scale=FALSE)
#```

```{r}
str(pmltraining)
names(pmltraining)
```

